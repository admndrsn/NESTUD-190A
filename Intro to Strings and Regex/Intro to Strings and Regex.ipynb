{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Regular Expressions in Python\n",
    "\n",
    "On Tuesday, the class utilized Python's NLTK in order to perform text analysis. Tuesday's module focused greatly on tokenizing parts of strings and then using the library's in-built functions to analyze those tokens. Today, we will be learning about another technique of text analysis that involves using a special type of code called \"regular expressions\". For this module, we will be using functions from the 're' library of Python. \n",
    "\n",
    "### Learning Goals:\n",
    "The goal of this lesson is to gain an introductory understanding of how regular expressions can be used with large portions of text to cleanly pull data from the text. Regular expressions can seem overwhelming at first, but with practice, they become easier to use. The goal is to add the usage of regular expressions to your text analysis 'toolbox'; from there, how you choose to analyze your own data is based on your own design and vision! Don't worry if you don't understand everything! Ask questions if you require assistance.\n",
    "\n",
    "\n",
    "### Lesson Outline:\n",
    "- Q&A regarding Tuesday's module content\n",
    "- Structure of Strings in code\n",
    "- Regular Expression Overview\n",
    "- findall, sub, and more\n",
    "- Examples (with Clayton's data)\n",
    "- Practice!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Strings in Python\n",
    "\n",
    "As you may recall from Tuesday, a string (in coding jargon) is a type of variable that consists of a sequence of characters in a particular order. Characters can be both letters and numbers, and the sequence in a string is ordered. Even though strings are fixed variables, it is still possible to manipuate them and gain more information from within them. In Python, strings exist in a fashion analogous to lists. Similar to how we can pick elements in order from an ordered list, we can do the same for characters within a Python string. One important fact to keep in mind is that Python indexing starts at 0; that is to say that the first element in any Python list structure is actually indexed at 0.\n",
    "\n",
    "Try running the code cell below to gain an understanding of string structure. Try and predict what will print before you print an output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "example = 'California'\n",
    "print(len(example)) #This function provides the length of a string. Tip: The length and final index of a string are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "print(example[0]) #We can reach an indexed value using the [] with the index number in the middle\n",
    "print(example[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "a\n",
      "l\n",
      "i\n",
      "f\n",
      "o\n",
      "r\n",
      "n\n",
      "i\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for elem in example:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a portion of a string, utilize the colon within your square brackets. For example [0:2] wil give you the 0th and 1st indexed characters in a string (but not the second!). As you can see, the splicing ability includes the first index, but not the last. If you would like to get everything from the start up to a certain index, leave the left side of the colon empty. If you would like to get everything from a certain index to the end of a string, leave the right side of the colon blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ca\n"
     ]
    }
   ],
   "source": [
    "print(example[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lif\n"
     ]
    }
   ],
   "source": [
    "print(example[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calif\n"
     ]
    }
   ],
   "source": [
    "print(example[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ornia\n"
     ]
    }
   ],
   "source": [
    "print(example[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you feel comfortable with strings? Ask questions if not!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "On Tuesday, you worked with Python's NLTK to tokenize words and sort/structure/manipulate them using the built functions. Regular expressions are an alternative way to 'search' for information within strings. At their most basic level, regular expressions are sequences of characters that define a pattern with which the computer searches. Regular expressions give us immense power by allowing us to search within extremly large portions of text for very specific types of text/information. \n",
    "\n",
    "Imagine that we are given a farm of various animals. Think of regular expressions as defining features that help us find exactly what we are looking for. In my farm, I want to search for animals that are brown, have 4 legs, and weigh more than 10 pounds. Each of those animal characteristics is analogous to a \"sequences of characters\" in the context of regular expressions. I may be looking for words that contain capital letters, or words that specifically start with a certain sequence of characters, similarly to how I am looking for brown animals, or animals with 4 legs.\n",
    "\n",
    "In the cells below, we will introduce some basic regular expression code, and the findall function within the 're' Python library. This function will allow us to transform our confusing regex code into tangible results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the package for regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.findall\n",
    "\n",
    "You can use `re.findall` to find all instances of some string/regex/pattern within a larger string.\n",
    "\n",
    "It is used with the syntax `re.findall(pattern, string)`, where `pattern` is the pattern that you want to look for in `string`. It returns all instances of that pattern in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is our example string\n",
    "example = 'The dog and cat and muskrat and snake and cow and mouse and moose and mare and deer and macaw and bear all went to the store.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can put the string that you want to look for\n",
    "re.findall('and', example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you call len on the list, it will tell you how many items there are\n",
    "len(re.findall('and', example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(' ', example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'e', ' ', 'd', 'o', 'g', ' ', 'a', 'n', 'd', ' ', 'c', 'a', 't', ' ', 'a', 'n', 'd', ' ', 'm', 'u', 's', 'k', 'r', 'a', 't', ' ', 'a', 'n', 'd', ' ', 's', 'n', 'a', 'k', 'e', ' ', 'a', 'n', 'd', ' ', 'c', 'o', 'w', ' ', 'a', 'n', 'd', ' ', 'm', 'o', 'u', 's', 'e', ' ', 'a', 'n', 'd', ' ', 'm', 'o', 'o', 's', 'e', ' ', 'a', 'n', 'd', ' ', 'm', 'a', 'r', 'e', ' ', 'a', 'n', 'd', ' ', 'd', 'e', 'e', 'r', ' ', 'a', 'n', 'd', ' ', 'm', 'a', 'c', 'a', 'w', ' ', 'a', 'n', 'd', ' ', 'b', 'e', 'a', 'r', ' ', 'a', 'l', 'l', ' ', 'w', 'e', 'n', 't', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 's', 't', 'o', 'r', 'e', '.']\n"
     ]
    }
   ],
   "source": [
    "# using '.' will return any character\n",
    "print(re.findall('.', example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mu', 'mo', 'mo', 'ma', 'ma']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can combine special characters like '.' with plain letters\n",
    "re.findall('m.', example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'and', 'cat', 'and', 'muskrat', 'and', 'snake', 'and', 'cow', 'and', 'mouse', 'and', 'moose', 'and', 'mare', 'and', 'deer', 'and', 'macaw', 'and', 'bear', 'all', 'went', 'to', 'the', 'store']\n"
     ]
    }
   ],
   "source": [
    "# '\\w' is the special character for any letter\n",
    "# '+' indicates that we want instances where there are one or more in a row\n",
    "print(re.findall('\\w+', example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'and', 'cat', 'and', 'mus', 'kra', 't', 'and', 'sna', 'ke', 'and', 'cow', 'and', 'mou', 'se', 'and', 'moo', 'se', 'and', 'mar', 'e', 'and', 'dee', 'r', 'and', 'mac', 'aw', 'and', 'bea', 'r', 'all', 'wen', 't', 'to', 'the', 'sto', 're']\n"
     ]
    }
   ],
   "source": [
    "# you can also specify that you want a certain amount of repeats of a character using {}\n",
    "print(re.findall('\\w{1,3}', example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muskrat ', 'mouse ', 'moose ', 'mare ', 'macaw ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '\\s' is the character for whitespace\n",
    "re.findall('m\\w+\\s', example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muskrat', 'mare', 'macaw']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use [] to indicate that the next character can come from any of the options within the brackets\n",
    "re.findall('m[u,a]\\w+\\S', example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '?' means that the before character is optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.sub\n",
    "\n",
    "If you wanted to substitute something in for all of the patterns that you found with `re.findall`, you could use `re.sub`. \n",
    "\n",
    "It is used with the syntax `re.sub(pattern, repl, string)`, where `pattern` is the pattern that you are looking for within `string`. The string that you want to replace `pattern` with is `repl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub('and m[u,a]\\w+\\S ', '',example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub(' and', ',',example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub(' and', ',',example, count=len(re.findall('and', example))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "\n",
    "The above functions are returning a single string, but sometimes you want to break you string up into smaller strings. You can use the method `.split()` to break up a string by a specific string and put them into a list.\n",
    "\n",
    "If you want to split up a string by a regular expression, you can use `re.split`, which takes the same arguments as `re.findall`, first the pattern that you want to split by, then the string that is to be split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if you don't put anything in the parenthesis after .split, it will default to splitting by spaces\n",
    "split_by_spaces = example.split()\n",
    "\n",
    "print(split_by_spaces)\n",
    "\n",
    "\n",
    "#sometimes it will be more helpful to split by a specific string\n",
    "split_by_and = example.split('and')\n",
    "\n",
    "print(split_by_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in your text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are opening the file 'coffee_133_152.txt' in read mode ('r'), and calling that item f\n",
    "with open('coffee_133_152.txt', 'r') as f:\n",
    "    #we then read all of the lines of that file (f.read) and assign that text to read_data\n",
    "    read_data = f.read()\n",
    "    \n",
    "print(read_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining those text files\n",
    "\n",
    "There are many different ways to combine the files into one corpus, but one way is to just concatenate each string directly into the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('coffee_1_43.txt', 'r') as f:\n",
    "    #we then read all of the lines of that file (f.read) and assign that text to read_data\n",
    "    read_data2 = f.read()\n",
    "\n",
    "with open('coffee_44_133.txt', 'r') as f:\n",
    "    #we then read all of the lines of that file (f.read) and assign that text to read_data\n",
    "    read_data3 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = read_data2 + '\\n' + read_data3 + '\\n' + read_data\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying all of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing additional packages\n",
    "\n",
    "# datascience is a library that was created for Data 8\n",
    "# it is mainly used for creating and manipulating tables\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas is similar to datascience, but has more features, \n",
    "# though with those features come a steeper learning curve\n",
    "import pandas as pd\n",
    "\n",
    "# pprint (pronounced pretty-print) allows us to print with\n",
    "# special formatting that makes things easier to read\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "# Counter counts the number of times that an item appears in a list\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# figuring out how much coffee actually comes up\n",
    "# note that we changed the corpus to be lower case \n",
    "# when we want to see how many times coffee appears\n",
    "coffee_mentions = re.findall('coffee', corpus.lower())\n",
    "\n",
    "print(len(coffee_mentions))\n",
    "print(coffee_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use findall to quickly get the context surrounding certain words\n",
    "re.findall('.{,30}coffee.{,30}', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the text also is about inter-american trade, \n",
    "# so we may want to know about references to america\n",
    "\n",
    "america_mentions = re.findall('america', corpus.lower())\n",
    "print('America count:')\n",
    "print(len(america_mentions))\n",
    "\n",
    "pan_america_mentions = re.findall('pan america', corpus.lower())\n",
    "print('\\nPan America count:')\n",
    "print(len(pan_america_mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use findall to quickly get the context surrounding certain words\n",
    "re.findall('.{,30}America.{,30}', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can look at the frequency of certain words. This is an alternate way to do it, though it would probably be better to use a package that is explicitly made for this sort of thing, like NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dictionary = Counter(re.findall(\"[A-Z]{2,}(?![a-z])|[A-Z][a-z]+(?=[A-Z])|[\\'\\w\\-]+\",corpus.lower()))\n",
    "pp.pprint(word_dictionary)\n",
    "\n",
    "# if you would rather have it as a table, you can uncomment the \n",
    "# pd.DataFrame.from_dict(word_dictionary, orient='index').sort(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary of pages\n",
    "\n",
    "First, we are going to try to make it so that we have a way of sorting through our text. One way to do that is to make a dictionary for each page. A dictionary is a data structure that consists of key-value pairs. Each key is linked to a value, so when you present the dictionary with a key, it returns the key's corresponding value. In our case, we are going to want to make page numbers our keys and the text that they link to our values.\n",
    "\n",
    "<img src='page_number.png' style='width:200px;'>\n",
    "\n",
    "Looking at how the pages are numbered, how do you think we can use regular expressions to pick out the page number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.findall('\\[\\d+\\]', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you inspect the values in the list above, you will notice that we're missing page values, so let's try a different regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page_numbers = re.findall('\\[.{1,5}\\]', corpus)\n",
    "page_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one still isn't complete, but it's better. Try inspecting the actual text to see what we can change to get more pages!\n",
    "\n",
    "Now that we know what the page numbers are, we can split the text between those points. We are going to use `re.split` instead of the built in `.split()` method because we want to search by more complex regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_pages = re.split('\\[.{1,5}\\]', corpus)[:-1]\n",
    "print(split_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our page numbers and their corresponding content split within lists, we are ready to combine them into a dictionary. We make use of the built in functions `zip` and `dict`, which combine corresponding elements in lists (`zip`) and then creates the dictionary (`dict`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_dictionary = dict(zip(page_numbers,split_pages))\n",
    "pp.pprint(page_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is how you call out a value of a dictionary\n",
    "print(page_dictionary['[5]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have to put in the page number in brackets that it is stored in the text as, so we can clean that up with some regular expression work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_page_numbers = [x.replace('[', '').replace(' ', '').replace(']', '') for x in page_numbers]\n",
    "clean_dictionary = dict(zip(clean_page_numbers,split_pages))\n",
    "\n",
    "print(clean_dictionary['5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the above dictionary entry for page 5 and the actual page below!\n",
    "\n",
    "<img src='page_5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a dictionary for each entry in the appendix\n",
    "\n",
    "Below is the pattern that seperates each entry of the appendix.\n",
    "\n",
    "<img src='appendix_37.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pulling out the appendix portion of the text\n",
    "appendix = corpus.split('V. APPENDICES')[1]\n",
    "\n",
    "# we split the text up by the appendix headers\n",
    "# the parenthesis around our regex mean that it will\n",
    "# remain in the returned list, as its own string\n",
    "split_by_appendix = re.split('(APPENDIX N[o,O,0)]. \\d+)', appendix)\n",
    "print(split_by_appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we pick out the appendix numbers to be our keys\n",
    "app_num = split_by_appendix[1::2]\n",
    "\n",
    "# picking out the content of the appendices\n",
    "app_content = split_by_appendix[2::2]\n",
    "\n",
    "# creating our dictionary\n",
    "appendix_dictionary = dict(zip(app_num,app_content))\n",
    "print(appendix_dictionary['APPENDIX NO. 37'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing a table that exists in the text\n",
    "\n",
    "<img src='page_125.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# at the bottom of page 125, there is a table\n",
    "page_125 = clean_dictionary['125']\n",
    "print(page_125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using a list comprehension to select the lines where there are lines that match the pattern\n",
    "# re.search returns True if the pattern is within the given string\n",
    "rows = [line for line in page_125.split('\\n') if re.search('\\w+\\s+\\d+,+', line)]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_rows = [re.split('(.+) (.+)', line)[1:3] for line in rows]\n",
    "table_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#building a datascience table with the information we have above\n",
    "quota_table = Table(['Country', 'Quota']).with_rows(table_rows)\n",
    "\n",
    "# cleaning up that table so that the quota numbers are integers\n",
    "refined_table = quota_table.with_column('Quota', [int(value.replace(',','')) for value in quota_table['Quota']])\n",
    "refined_table.show(refined_table.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting a barchart with the built in barh function\n",
    "refined_table.barh('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "A helpful website to practice all of these regular expressions is https://regexone.com\n",
    "\n",
    "Here is the documentation for re https://docs.python.org/2/library/re.html#module-re\n",
    "\n",
    "And here is a quick cheatsheet for regex http://www.rexegg.com/regex-quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
